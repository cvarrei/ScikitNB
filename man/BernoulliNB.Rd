% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BernoulliNB.R
\name{BernoulliNB}
\alias{BernoulliNB}
\title{Initialize Bernoulli Naive Bayes Classifier}
\description{
Initialize Bernoulli Naive Bayes Classifier

Initialize Bernoulli Naive Bayes Classifier
}
\examples{

## ------------------------------------------------
## Method `BernoulliNB$new`
## ------------------------------------------------

# Initialize the Bernoulli Naive Bayes Classifier with 2 cores and verbose output
bernoulli_nb <- BernoulliNB$new(n_cores = 2)


## ------------------------------------------------
## Method `BernoulliNB$preprocess`
## ------------------------------------------------

# Assuming 'X_train' and 'X_test' are your explanatory and target variables respectively

bernoulli_nb <- BernoulliNB$new(n_cores = 2)
preprocess_X = bernoulli_nb$preprocess(X_train, X_test)
X_train_vectorized = preprocess_X[[1]]
X_test_vectorized = preprocess_X[[2]]


## ------------------------------------------------
## Method `BernoulliNB$fit`
## ------------------------------------------------

# Assuming 'X_train_vectorized' is your preprocessed training dataset

bernoulli_nb <- BernoulliNB$new(n_cores = 2, verbose = TRUE)
bernoulli_nb$fit(X_train_vectorized, y_train)


## ------------------------------------------------
## Method `BernoulliNB$joint_log_likelihood`
## ------------------------------------------------

# Assuming 'X' is your vectorized test dataset
jll <- bernoulli_nb$joint_log_likelihood(X)


## ------------------------------------------------
## Method `BernoulliNB$predict`
## ------------------------------------------------

# Assuming 'X' is your vectorized test dataset
# Ensure that the model has been trained using fit method
y_pred <- bernoulli_nb$predict(X)


## ------------------------------------------------
## Method `BernoulliNB$predict_log_proba`
## ------------------------------------------------

# Assuming 'X' is your vectorized test dataset
log_probs <- bernoulli_nb$predict_log_proba(X)


## ------------------------------------------------
## Method `BernoulliNB$predict_proba`
## ------------------------------------------------

# Assuming `X` is your preprocessed test dataset
probs <- bernoulli_nb$predict_proba(X)


## ------------------------------------------------
## Method `BernoulliNB$score`
## ------------------------------------------------

# Assuming 'X' and 'y' are your test dataset and labels
# Ensure that the model has been trained using fit method
results <- bernoulli_nb$score(X, y)


## ------------------------------------------------
## Method `BernoulliNB$performances`
## ------------------------------------------------

# Assuming 'X_test' and 'y_test' are your test dataset and labels
# Ensure that the model has been trained using fit method
results <- bernoulli_nb$score(X_test, y_test)


## ------------------------------------------------
## Method `BernoulliNB$print`
## ------------------------------------------------

# Assuming the Bernoulli Naive Bayes model has been trained
bernoulli_nb <- BernoulliNB$new(n_cores = 2, verbose = TRUE)
bernoulli_nb$fit(X_train_vectorized)
bernoulli_nb$print()

# OR
print(bernoulli_nb)


## ------------------------------------------------
## Method `BernoulliNB$summary`
## ------------------------------------------------

# Assuming the Bernoulli Naive Bayes model has been trained

bernoulli_nb$summary()

# OR

summary(bernoulli_nb)


## ------------------------------------------------
## Method `BernoulliNB$plot_roccurve`
## ------------------------------------------------

# Assuming 'X' and 'y_test' are your preprocessed test dataset and actual labels
# This is the case of a binary classification

bernoulli_nb$plot_roccurve(X, y_test, positive = "YourPositiveClassLabel")


## ------------------------------------------------
## Method `BernoulliNB$plot_confusionmatrix`
## ------------------------------------------------

# Assuming 'X' and 'y_test' are your preprocessed test dataset and actual labels
bernoulli_nb$plot_confusionmatrix(X, y_test)


## ------------------------------------------------
## Method `BernoulliNB$top_logproba`
## ------------------------------------------------

# Assuming 'class' is a specific class from our dataset.
bernoulli_nb$top_logproba("YourClass")

}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-BernoulliNB-new}{\code{BernoulliNB$new()}}
\item \href{#method-BernoulliNB-preprocess}{\code{BernoulliNB$preprocess()}}
\item \href{#method-BernoulliNB-fit}{\code{BernoulliNB$fit()}}
\item \href{#method-BernoulliNB-joint_log_likelihood}{\code{BernoulliNB$joint_log_likelihood()}}
\item \href{#method-BernoulliNB-predict}{\code{BernoulliNB$predict()}}
\item \href{#method-BernoulliNB-predict_log_proba}{\code{BernoulliNB$predict_log_proba()}}
\item \href{#method-BernoulliNB-predict_proba}{\code{BernoulliNB$predict_proba()}}
\item \href{#method-BernoulliNB-score}{\code{BernoulliNB$score()}}
\item \href{#method-BernoulliNB-performances}{\code{BernoulliNB$performances()}}
\item \href{#method-BernoulliNB-print}{\code{BernoulliNB$print()}}
\item \href{#method-BernoulliNB-summary}{\code{BernoulliNB$summary()}}
\item \href{#method-BernoulliNB-plot_roccurve}{\code{BernoulliNB$plot_roccurve()}}
\item \href{#method-BernoulliNB-plot_confusionmatrix}{\code{BernoulliNB$plot_confusionmatrix()}}
\item \href{#method-BernoulliNB-top_logproba}{\code{BernoulliNB$top_logproba()}}
\item \href{#method-BernoulliNB-clone}{\code{BernoulliNB$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-new"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-new}{}}}
\subsection{Method \code{new()}}{
This method initializes an instance of the Bernoulli Naive Bayes Classifier.
It sets up the environment, including verifying and setting the number of processor cores
to be used for computation and optionally provides instructions for using the classifier.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$new(
  alpha = 1,
  fit_prior = TRUE,
  class_prior = NULL,
  n_cores = 1,
  verbose = T
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{alpha}}{Sets the Laplace smoothing parameter}

\item{\code{fit_prior}}{Sets whether to learn class prior probabilities}

\item{\code{class_prior}}{Sets the prior probabilities of the classes}

\item{\code{n_cores}}{The number of processor cores to use for calculations.
The method verifies if the specified number of cores is available.}

\item{\code{verbose}}{A logical value indicating whether to print detailed messages
about the initialization process. Default is TRUE.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
If the specified number of cores (n_cores) exceeds the number of available cores,
         the function throws an error. When verbose is TRUE, the function prints
         instructions on the console for preprocessing and using the classifier.
         This constructor allows you to create an instance of your BernoulliNB class with
         specified parameters.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Initialize the Bernoulli Naive Bayes Classifier with 2 cores and verbose output
bernoulli_nb <- BernoulliNB$new(n_cores = 2)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-preprocess"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-preprocess}{}}}
\subsection{Method \code{preprocess()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$preprocess(
  X_train,
  X_test,
  to_lower = T,
  rm_punctuation = T,
  rm_numbers = T,
  rm_stopwords = stopwords("english"),
  strip_whitespace = T
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X_train}}{A vector containing the explanatory variables.}

\item{\code{X_test}}{A vector containing the target variable.}

\item{\code{to_lower}}{A boolean to change our corpus to lowercase.}

\item{\code{rm_punctuation}}{A boolean to remove punctuation from our corpus.}

\item{\code{rm_numbers}}{A boolean to remove numbers from our corpus.}

\item{\code{rm_stopwords}}{Stopwords to remove or NULL.}

\item{\code{strip_whitespace}}{A boolean to strip white spaces from our corpus}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The function contains two other functions :
         'preprocess_corpus(X)' Takes a vector of text documents, creates a text
         corpus, and applies various preprocessing steps such as converting to
         lowercase, removing punctuation, removing numbers, removing stopwords,
         and stripping whitespace. It returns the preprocessed corpus.
         'get_bow(X,vocabulary)' takes a vector of text documents and a vocabulary.
         It uses the 'preprocess_corpus' function to preprocess the text, creates
         a binary bag-of-words. It returns the bag-of-words as a sparse matrix.
}

\subsection{Returns}{
A list containing the vectorized representations of the training
and test data.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X_train' and 'X_test' are your explanatory and target variables respectively

bernoulli_nb <- BernoulliNB$new(n_cores = 2)
preprocess_X = bernoulli_nb$preprocess(X_train, X_test)
X_train_vectorized = preprocess_X[[1]]
X_test_vectorized = preprocess_X[[2]]

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-fit"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-fit}{}}}
\subsection{Method \code{fit()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$fit(X, y, verbose = T)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A vectorized matrix of explanatory features used for training.}

\item{\code{y}}{a vector of our target variable containing our classes.}

\item{\code{verbose}}{A logical value indicating whether to print detailed messages
about the training process. Default is TRUE.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The methof performs Bernoulli Naive Bayes model training by counting feature
         occurrences, applying Laplace smoothing, removing problematic features, and updating model
         parameters.
}

\subsection{Returns}{
The method does not return anything but updates the model's internal state
        with the training results, including feature statistics and performance metrics.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X_train_vectorized' is your preprocessed training dataset

bernoulli_nb <- BernoulliNB$new(n_cores = 2, verbose = TRUE)
bernoulli_nb$fit(X_train_vectorized, y_train)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-joint_log_likelihood"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-joint_log_likelihood}{}}}
\subsection{Method \code{joint_log_likelihood()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$joint_log_likelihood(X)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A matrix containing the vectorized test set explanatory features.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method checks and selects features, ensures the compatibility of feature numbers,
         calculates inverse log probabilities, computes joint log probabilities, updates them with class
         priors, and returns the results.
}

\subsection{Returns}{
A matrix of joint log probabilities, where each row corresponds to an observation
        and each column to a class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' is your vectorized test dataset
jll <- bernoulli_nb$joint_log_likelihood(X)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-predict"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-predict}{}}}
\subsection{Method \code{predict()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$predict(X)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A matrix containing the vectorized test set explanatory features.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method first verifies if the model has been trained with the `fit` method.
         Then it calculates the joint_log_likelihood for the input samples, find the indices of
         the predicted classes using parallel processing, maps them to class labels, and returns
         the predicted classes.
}

\subsection{Returns}{
A vector of predicted class labels for each observation in the test dataset.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' is your vectorized test dataset
# Ensure that the model has been trained using fit method
y_pred <- bernoulli_nb$predict(X)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-predict_log_proba"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-predict_log_proba}{}}}
\subsection{Method \code{predict_log_proba()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$predict_log_proba(X)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A vectorized matrix containing test explanatory features.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method calculates the joint_log_likelihood for the input samples. Then it normalizes
         the jll by the marginal probability P(x), and calculates and return the log_probabilities.
}

\subsection{Returns}{
A matrix of log probabilities, where each row corresponds to an observation
        and each column to a class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' is your vectorized test dataset
log_probs <- bernoulli_nb$predict_log_proba(X)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-predict_proba"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-predict_proba}{}}}
\subsection{Method \code{predict_proba()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$predict_proba(X)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A vectorized matrix containing test explanatory features.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method first checks if the model has been trained.
         It then calls the 'predict_log_proba' method to obtain the log probabilities
         and applies the exponential function to these values to get the posterior probabilities.
}

\subsection{Returns}{
A matrix of posterior probabilities, where each row corresponds to an observation
        and each column to a class. These probabilities are derived from the log probabilities
        computed by the 'predict_log_proba' method.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming `X` is your preprocessed test dataset
probs <- bernoulli_nb$predict_proba(X)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-score"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-score}{}}}
\subsection{Method \code{score()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$score(X, y, verbose = T)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A vectorized matrix containing test explanatory features.}

\item{\code{y}}{A vector containing the actual class labels of the test set.}

\item{\code{verbose}}{A boolean indicating whether to print detailed output (default is TRUE).}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method predicts class labels for the test set, constructs a confusion matrix,
         and calculates error rate, recall, and precision. It also computes a 95% confidence interval
         for the error rate. The results are returned as a list and can optionally be printed in detail.
}

\subsection{Returns}{
A list containing the confusion matrix, error rate, 95% confidence interval for the error rate,
        recall, and precision for each class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' and 'y' are your test dataset and labels
# Ensure that the model has been trained using fit method
results <- bernoulli_nb$score(X, y)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-performances"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-performances}{}}}
\subsection{Method \code{performances()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$performances()}\if{html}{\out{</div>}}
}

\subsection{Details}{
The method predicts class labels for the train set, constructs a confusion matrix,
         and calculates error rate, recall, and precision. It also computes a 95% confidence interval
         for the error rate.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X_test' and 'y_test' are your test dataset and labels
# Ensure that the model has been trained using fit method
results <- bernoulli_nb$score(X_test, y_test)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-print"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-print}{}}}
\subsection{Method \code{print()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$print()}\if{html}{\out{</div>}}
}

\subsection{Details}{
The method checks if the model has been trained and then prints
         the number of classes in the target variable, the number of observations
         in the sample, and the error rate on the training set along with its 95%
         confidence interval. This provides a quick overview of the model's training performance.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming the Bernoulli Naive Bayes model has been trained
bernoulli_nb <- BernoulliNB$new(n_cores = 2, verbose = TRUE)
bernoulli_nb$fit(X_train_vectorized)
bernoulli_nb$print()

# OR
print(bernoulli_nb)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-summary"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-summary}{}}}
\subsection{Method \code{summary()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$summary()}\if{html}{\out{</div>}}
}

\subsection{Details}{
The method checks if the model has been trained.
         It prints details such as the number of classes, class labels, number of features,
         size of the training sample, prior probabilities of each class,
         classifier performance metrics (confusion matrix, error rate, recall, precision) on the training dataset,
         and the classification function (features significance).
         The summary provides a deep insight into the model's characteristics and performance.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming the Bernoulli Naive Bayes model has been trained

bernoulli_nb$summary()

# OR

summary(bernoulli_nb)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-plot_roccurve"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-plot_roccurve}{}}}
\subsection{Method \code{plot_roccurve()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$plot_roccurve(X, y_test, positive = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A matrix containing the preprocessed test set explanatory variables.}

\item{\code{y_test}}{A vector containing the actual class labels of the test set.}

\item{\code{positive}}{An optional parameter specifying the positive class label in a binary classification scenario.
It is required when the model is trained on a binary classification task.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
For multi-class classification (more than two classes), the method generates a One-vs-Rest (OVR)
         multi-class ROC curve. For binary classification, it plots a ROC curve for the specified positive class.
         The Area Under the Curve (AUC) is calculated for each class. The method checks if the model
         has been trained before generating the ROC curve.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' and 'y_test' are your preprocessed test dataset and actual labels
# This is the case of a binary classification

bernoulli_nb$plot_roccurve(X, y_test, positive = "YourPositiveClassLabel")

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-plot_confusionmatrix"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-plot_confusionmatrix}{}}}
\subsection{Method \code{plot_confusionmatrix()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$plot_confusionmatrix(X, y_test)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{A matrix containing the test features.}

\item{\code{y_test}}{A vector containing the actual class labels of the test set.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method first checks if the model has been trained.
         It then predicts the class labels for the test set using the specified prediction type
         and constructs a confusion matrix. This matrix is visualized using the `corrplot` package,
         with a color gradient representing the frequency of each cell in the matrix. The method
         handles missing classes by adding zero-filled columns to ensure a complete matrix.
}

\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'X' and 'y_test' are your preprocessed test dataset and actual labels
bernoulli_nb$plot_confusionmatrix(X, y_test)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-top_logproba"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-top_logproba}{}}}
\subsection{Method \code{top_logproba()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$top_logproba(class)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{class}}{The class from which we want to extract the features.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
The method first checks if the model has been trained.
         It then predicts the class labels for the test set and constructs a confusion matrix.
         This matrix is visualized using the 'corrplot' package, with a color gradient representing
         the frequency of each cell in the matrix. The method handles missing classes by adding zero-filled columns to ensure a complete matrix.
}

\subsection{Returns}{
A dataframe of the best words and their log_probabiliities
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assuming 'class' is a specific class from our dataset.
bernoulli_nb$top_logproba("YourClass")

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BernoulliNB-clone"></a>}}
\if{latex}{\out{\hypertarget{method-BernoulliNB-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{BernoulliNB$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
